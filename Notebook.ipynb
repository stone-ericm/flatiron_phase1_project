{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = pd.read_csv('post_wiki_scrape-Copy1.csv')\n",
    "working_df = working_df.set_index(['start_year', 'title'])\n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from inspect import currentframe, getframeinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imports = {}\n",
    "\n",
    "# Importing all the provided CSVs and TSVs to a dictionary\n",
    "for file in os.listdir(\"zippedData\"):\n",
    "    print(file)\n",
    "    if file[-3:] == 'csv':\n",
    "        data_imports[file[:-4]] = pd.read_csv('zippedData/' + str(file))\n",
    "    elif file[-3:] == 'tsv':\n",
    "        data_imports[file[:-4]] = pd.read_csv('zippedData/' + str(file), sep = '\\t', encoding= 'unicode_escape')\n",
    "\n",
    "print(\"Finished import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting with Bom.Movie_Gross, I want to set the index as release year and then title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_movie_gross = data_imports['bom.movie_gross']\n",
    "# bom_movie_gross[bom_movie_gross['title'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_movie_gross = bom_movie_gross.rename(columns = {'year': 'start_year'})\n",
    "bom_movie_gross = bom_movie_gross.set_index(['start_year', 'title'])\n",
    "bom_movie_gross.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In an effort to explore the data, we'll merge title.basics with title.ratings into imdb_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics = data_imports['title.basics']\n",
    "title_ratings = data_imports['title.ratings']\n",
    "\n",
    "title_basics = title_basics.set_index('tconst')\n",
    "title_ratings = title_ratings.set_index('tconst')\n",
    "imdb_df = title_basics.join(title_ratings, on='tconst')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge imdb_df with tmdb.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_movies = data_imports['tmdb.movies']\n",
    "tmdb_movies = tmdb_movies.drop_duplicates(subset = ['id'])\n",
    "tmdb_movies['start_year'] = tmdb_movies['release_date'].apply(lambda x: int(x[:4]))\n",
    "tmdb_movies = tmdb_movies.set_index(['start_year', 'title'])\n",
    "tmdb_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = imdb_df.rename(columns = {'primary_title': \"title\"})\n",
    "imdb_df = imdb_df.reset_index()\n",
    "working_df = imdb_df.set_index(['start_year', 'title']).join(tmdb_movies, how='outer', lsuffix='_imdb', rsuffix='_mvdb')\n",
    "\n",
    "\n",
    "working_df = working_df.drop(columns=['Unnamed: 0', 'vote_average', 'vote_count', 'popularity', 'genre_ids', 'id'])\n",
    "# working_df = working_df.fillna(value = {'genres': 'Unknown'})\n",
    "\n",
    "working_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in bom_movie_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.join(bom_movie_gross, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in tn_movie_budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_movie_budgets = data_imports['tn.movie_budgets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of movies we'll have to work with if we join working_df and tn_movie_budgets\n",
    "\n",
    "# movie_titles_working = []\n",
    "# movie_titles_tn = []\n",
    "# for year, title in working_df.index:\n",
    "#     movie_titles_working.append(title)\n",
    "\n",
    "# for title in tn_movie_budgets['movie']:\n",
    "#     movie_titles_tn.append(title)\n",
    "    \n",
    "# len(set(movie_titles_working) & set(movie_titles_tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['release_date'] = pd.to_datetime(working_df['release_date'])\n",
    "tn_movie_budgets['start_year'] = pd.DatetimeIndex(tn_movie_budgets['release_date']).year\n",
    "tn_movie_budgets = tn_movie_budgets.rename(columns={'movie':'title'})\n",
    "tn_movie_budgets = tn_movie_budgets.set_index(['start_year', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn_movie_budgets.head()\n",
    "working_df = working_df.join(tn_movie_budgets, how='outer', lsuffix='_imdb', rsuffix='_tn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop movies from before 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.reset_index()\n",
    "working_df = working_df[working_df['start_year'] > 2000]\n",
    "working_df = working_df.set_index(['start_year', 'title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaN genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.dropna(subset=['genres'])\n",
    "working_df = working_df[working_df['original_language'] == 'en']\n",
    "working_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping wikipedia for production budgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I had to decide whether it was better to remove foreign films from the dataset or spend the time it would require to write code to account for each individual foreign currency found through scrapping. I ultimately decided, both due to the scope of the project (Microsoft being an American company) and the marginal number of foreign films remaining in my dataset that it was better to simply return None for budgets not in US dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in the string, isolated as a budget, and returns a number of type int\n",
    "\n",
    "\n",
    "def convert_budget_to_int(budget, debug):\n",
    "\n",
    "    #     Checks for various non-alphanumeric characters\n",
    "\n",
    "    if type(budget) == int:\n",
    "        return budget\n",
    "    if type(budget) == float:\n",
    "        return int(budget)\n",
    "    if budget.startswith('$CAD'):\n",
    "        return None\n",
    "    if budget.startswith('$') or budget.startswith('US$'):\n",
    "        if budget[0] == '<':\n",
    "            budget = budget[1:]\n",
    "            \n",
    "#  Enable for Avatar 2009, breaks other movies\n",
    "\n",
    "\n",
    "#         if '$' in budget[3:]:\n",
    "#             temp = budget[3:]\n",
    "#             budget = budget[:temp.index('$')+3]\n",
    "        while '[' in budget:\n",
    "            budget = budget.replace(\n",
    "                budget[budget.index('['):budget.index(']')+1], '')\n",
    "        if '–' in budget:\n",
    "            currency = ''\n",
    "            for i in budget:\n",
    "                if not i.isnumeric():\n",
    "                    currency = currency + i\n",
    "                else:\n",
    "                    break\n",
    "            if debug:\n",
    "                print(budget, \"Middle of dash check\")\n",
    "            budget = budget[budget.index('–')+1:]\n",
    "            budget = currency + budget\n",
    "        if '-' in budget:\n",
    "            currency = ''\n",
    "            for i in budget:\n",
    "                if not i.isnumeric():\n",
    "                    currency = currency + i\n",
    "                else:\n",
    "                    break\n",
    "            if debug:\n",
    "                print(budget, \"Middle of dash check\")\n",
    "            budget = budget[budget.index('-')+1:]\n",
    "            budget = currency + budget\n",
    "        if '—' in budget:\n",
    "            currency = ''\n",
    "            for i in budget:\n",
    "                if not i.isnumeric():\n",
    "                    currency = currency + i\n",
    "                else:\n",
    "                    break\n",
    "            if debug:\n",
    "                print(budget, \"Middle of dash check\")\n",
    "            budget = budget[budget.index('—')+1:]\n",
    "            budget = currency + budget\n",
    "        if debug:\n",
    "            print(budget)\n",
    "\n",
    "#     Using regex because for some reason ' ' would not be recognized for certain movies\n",
    "        if bool(re.search(r\"\\s\", budget)):\n",
    "            whitespace_index = re.search(r\"\\s\", budget).start()\n",
    "            if budget[whitespace_index-1].isnumeric():\n",
    "                number = budget[:whitespace_index]\n",
    "                word = budget[whitespace_index+1:]\n",
    "            else:\n",
    "                whitespace_index = re.search(\n",
    "                    r\"\\s\", budget[:whitespace_index]+budget[whitespace_index+1:]).start()\n",
    "                number = budget[:whitespace_index+1]\n",
    "                word = budget[whitespace_index+2:]\n",
    "            if debug:\n",
    "                print(word)\n",
    "                print(number)\n",
    "\n",
    "        else:\n",
    "            number, word = budget, ''\n",
    "        if debug:\n",
    "            print(number, 'Before \\'.\\' check')\n",
    "        if '.' in number:\n",
    "            left, right = number.split('.')\n",
    "            decimal_places = len(right)\n",
    "            number = number.replace('.', '')\n",
    "\n",
    "#     Replacing instnaces of million and crore (Indian for ten million) with the proper number of zeroes\n",
    "\n",
    "        if 'crore' in word.lower():\n",
    "            try:\n",
    "                number = number + '0000000'[decimal_places:]\n",
    "            except:\n",
    "                number = number + '0000000'\n",
    "        elif 'million' in word.lower():\n",
    "            try:\n",
    "                number = number + '000000'[decimal_places:]\n",
    "            except:\n",
    "                number = number + '000000'\n",
    "\n",
    "        if ',' in number:\n",
    "            number = number.replace(',', '')\n",
    "\n",
    "        budget = budget.strip()\n",
    "        if debug:\n",
    "            print(budget)\n",
    "\n",
    "        if budget[0] == '$':\n",
    "            number = number.replace('$', '')\n",
    "        elif budget[:3] == 'US$':\n",
    "            number = number.replace('US$', '')\n",
    "\n",
    "        return int(number)\n",
    "\n",
    "# Replaces spaces in a URL with %20\n",
    "\n",
    "\n",
    "def urlify(in_string):\n",
    "    return \"%20\".join(in_string.split())\n",
    "\n",
    "\n",
    "'''Uses Wikipedia's API to search for movies. \n",
    "In practice I would search by the title and year to reduce the chance of an incorrect match'''\n",
    "\n",
    "\n",
    "def wiki_search(search):\n",
    "    url = \"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=&list=search&srsearch={}\".format(\n",
    "        urlify(search))\n",
    "    response = requests.get(url=url)\n",
    "\n",
    "    try:\n",
    "        return(response.json()['query']['search'][0]['pageid'])\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "\n",
    "'''The called function which managed the search for movies on Wikipedia, \n",
    "the isolating of the budget string, and ultimately the return of the budget as an integer'''\n",
    "\n",
    "\n",
    "def wiki_grab(search, debug=False):\n",
    "    searches_to_ignore = ['#Stuck 2014',\n",
    "                          'House of Black Wings 2010',\n",
    "                          'Restoring a Masterpiece: The Renovation of Eastman Theatre 2010',\n",
    "                          'Avatar: Special Edition 2010',\n",
    "                          'The Forgotten Jewel 2010',\n",
    "                          'Birth of a Party 2011'\n",
    "                          ]\n",
    "    if search[0] == '#':\n",
    "        return None\n",
    "    if search in searches_to_ignore:\n",
    "        return None\n",
    "    pageid = wiki_search(search)\n",
    "    if debug:\n",
    "        print(pageid)\n",
    "    if pageid is None:\n",
    "        return None\n",
    "    url = 'https://en.wikipedia.org/w/api.php?action=parse&format=json&pageid={}&prop=text&formatversion=2'.format(\n",
    "        pageid)\n",
    "    if debug:\n",
    "        print(url)\n",
    "    response = requests.get(url=url)\n",
    "    soup = BeautifulSoup(response.json()['parse']['text'])\n",
    "\n",
    "    if 'Budget</th>' in str(soup):\n",
    "        if soup.find(text='Budget').next.text:\n",
    "            return convert_budget_to_int(soup.find(text='Budget').next.text, debug)\n",
    "        elif '(gross)' in soup.find(text='Budget').next.text:\n",
    "            gross = soup.find('li', text=re.compile(r' .+(\\(gross\\))')).text\n",
    "            gross = gross.replace(' (gross)', '')\n",
    "            gross = convert_budget_to_int(gross, debug)\n",
    "            return(gross)\n",
    "        elif re.compile(r' \\d') in soup.find(text='Budget').next.li.text:\n",
    "            return(soup.find('li', text=re.compile(r' \\d')))\n",
    "\n",
    "# A test run\n",
    "# print(wiki_grab(\"Habermann 2010\", True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['budget_wiki'] = np.nan\n",
    "for year, title in working_df[working_df['budget_wiki'].isna()].index.values.tolist():\n",
    "    try:\n",
    "#         Do not search again in the senario that we're running this code multiple times due to error\n",
    "        if working_df.loc[(year, title), 'budget_wiki'].values[0] == -1:\n",
    "            continue\n",
    "        print(title, year)\n",
    "        budget = wiki_grab(title + ' ' + str(year))\n",
    "        if budget == None:\n",
    "            working_df.loc[(year, title), 'budget_wiki'] = -1\n",
    "        else:\n",
    "            working_df.loc[(year, title), 'budget_wiki'] = budget\n",
    "        print(working_df.loc[(year, title), 'budget_wiki'])\n",
    "    except:\n",
    "        working_df.loc[(year, title), 'budget_wiki'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save my work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_df.to_csv('post_wiki_scrape.csv')\n",
    "\n",
    "working_df = pd.read_csv('post_wiki_scrape.csv')\n",
    "working_df = working_df.set_index(['start_year', 'title'])\n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert financial columns to int64 for comparison\n",
    "\n",
    "def convert_columns_to_int(budget):\n",
    "    try:\n",
    "        return int(float(budget))\n",
    "    except:\n",
    "        return convert_budget_to_int(budget, False)\n",
    "\n",
    "for column in ['domestic_gross_imdb', 'foreign_gross', 'production_budget', 'domestic_gross_tn', 'worldwide_gross', 'budget_wiki']:\n",
    "    working_df[column] = working_df[column].fillna(-1)\n",
    "    working_df[column] = working_df[column].apply(lambda x: convert_columns_to_int(x))\n",
    "    working_df[column] = working_df[column].astype('int64')\n",
    "\n",
    "working_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Derive a working worldwide gross and working budget based on the data gathered with a\n",
    "preference for information from IMDB and Wikipedia based on token examinations of the datasets\n",
    "'''\n",
    "\n",
    "working_df['working_wwg'] = working_df.apply(\n",
    "    lambda x: x['domestic_gross_imdb'] + x['foreign_gross'] if x['domestic_gross_imdb'] > -1 and x['foreign_gross'] > -1 \n",
    "        else x['worldwide_gross'], axis = 1)\n",
    "working_df['working_budget'] = working_df.apply(\n",
    "    lambda x: x['budget_wiki'] if x['budget_wiki'] > -1 else x['production_budget'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df['roi'] = working_df.apply(lambda x: x['working_wwg'] - x['working_budget'], axis = 1)\n",
    "working_df = working_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split 'genre' column into genre1, genre2, genre3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum amount of commas in the genres column\n",
    "comma_counter = 0\n",
    "\n",
    "for each in working_df['genres']:\n",
    "    if type(each) == str:\n",
    "        current_count = each.count(',')\n",
    "        if current_count > comma_counter:\n",
    "            comma_counter = current_count\n",
    "    \n",
    "comma_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[['genre1', 'genre2', 'genre3']] = working_df['genres'].str.split(',', expand=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replacing NaN with \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.fillna(value = {\n",
    "    'genres': 'Unknown', 'genre1': 'Unknown', 'genre3': 'Unknown', 'genre2': 'Unknown'\n",
    "})\n",
    "\n",
    "analysis_df = working_df[[\n",
    "    'runtime_minutes',\n",
    "    'genres',\n",
    "    'genre1',\n",
    "    'genre2',\n",
    "    'genre3',\n",
    "    'working_wwg',\n",
    "    'working_budget',\n",
    "    'roi'\n",
    "]].copy()\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analysis_df[analysis_df['roi'] != 0]\n",
    "analysis_df = analysis_df[analysis_df['working_wwg'] != -1]\n",
    "analysis_df = analysis_df[analysis_df['working_budget'] != -1]\n",
    "analysis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analysis_df.reset_index()\n",
    "analysis_df= analysis_df.rename(columns = {'start_year': 'year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll break up the dataframe along certain budget markers and create series through which we can analyse the performance of different genres\n",
    "\n",
    "Note that this method double and tripple counts certain movies with more than one listed genre, which is why it's important for us to eliminate genres with too few examples to prevent skewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_roi = pd.concat([pd.Series(analysis_df['roi'].values, analysis_df['genre1']),\n",
    "                       pd.Series(analysis_df['roi'].values, analysis_df['genre2']),\n",
    "                       pd.Series(analysis_df['roi'].values, analysis_df['genre3'])])\n",
    "\n",
    "analysis_df_1mil = analysis_df[analysis_df['working_budget'] >= 1000000].copy()\n",
    "\n",
    "genre_roi1 = pd.concat([pd.Series(analysis_df_1mil['roi'].values, analysis_df_1mil['genre1']),\n",
    "                       pd.Series(analysis_df_1mil['roi'].values, analysis_df_1mil['genre2']),\n",
    "                       pd.Series(analysis_df_1mil['roi'].values, analysis_df_1mil['genre3'])])\n",
    "\n",
    "analysis_df_10mil = analysis_df[analysis_df['working_budget'] >= 10000000].copy()\n",
    "\n",
    "genre_roi10 = pd.concat([pd.Series(analysis_df_10mil['roi'].values, analysis_df_10mil['genre1']),\n",
    "                       pd.Series(analysis_df_10mil['roi'].values, analysis_df_10mil['genre2']),\n",
    "                       pd.Series(analysis_df_10mil['roi'].values, analysis_df_10mil['genre3'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check how many of each genre we have so we can prevent skewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(genre_roi).reset_index()['index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(genre_roi1).reset_index()['index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(genre_roi10).reset_index()['index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_roi = genre_roi.drop(labels=['Reality-TV', 'Musical'])\n",
    "genre_roi1 = genre_roi1.drop(labels=['Reality-TV', 'Musical'])\n",
    "genre_roi10 = genre_roi10.drop(labels=['Western', 'Musical'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we graph these sets, we're going to reset the index and properly name the roi column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_roi_df = pd.DataFrame(genre_roi).reset_index().rename(columns={0:'roi'})\n",
    "genre_roi1_df = pd.DataFrame(genre_roi1).reset_index().rename(columns={0:'roi'})\n",
    "genre_roi10_df = pd.DataFrame(genre_roi10).reset_index().rename(columns={0:'roi'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General genre return on investment breakdown (no budget floor, excluded genres with fewer than 10 films in dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = genre_roi_df.groupby(\"index\")[\"roi\"].mean().sort_values().iloc[::-1].index\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "ax = sns.boxplot(x=genre_roi_df['index'], y=genre_roi_df['roi'], data=(genre_roi_df), order=my_order)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
    "plt.setp(ax.get_yticklabels(), fontsize = 10)\n",
    "\n",
    "ax.set_title('Profit by Genre since 2000', fontsize = 17)\n",
    "ax.set_xlabel('Genre', fontsize=15);\n",
    "ax.set_ylabel('Return on Investment (in Billions)', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General genre return on investment breakdown (budget >$1 million,  excluded genres with fewer than 10 films in dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = genre_roi1_df.groupby(\"index\")[\"roi\"].mean().sort_values().iloc[::-1].index\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "ax = sns.boxplot(x=genre_roi1_df['index'], y=genre_roi1_df['roi'], data=(genre_roi1_df), order=my_order)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
    "plt.setp(ax.get_yticklabels(), fontsize = 10)\n",
    "\n",
    "ax.set_title('Profit by Genre since 2000 (Budget > $1 Million)', fontsize = 17)\n",
    "ax.set_xlabel('Genre', fontsize=15);\n",
    "ax.set_ylabel('Return on Investment (in Billions)', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General genre return on investment breakdown (budget >$10 million,  excluded genres with fewer than 10 films in dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = genre_roi10_df.groupby(\"index\")[\"roi\"].mean().sort_values().iloc[::-1].index\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "ax = sns.boxplot(x=genre_roi10_df['index'], y=genre_roi10_df['roi'], data=(genre_roi10_df), order=my_order)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, fontsize=10)\n",
    "plt.setp(ax.get_yticklabels(), fontsize = 10)\n",
    "\n",
    "ax.set_title('Profit by Genre since 2000 (Budget > $10 Million)', fontsize = 17)\n",
    "ax.set_xlabel('Genre', fontsize=15);\n",
    "ax.set_ylabel('Return on Investment (in millons)', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_roi2_scifi = pd.DataFrame(pd.concat([pd.Series(analysis_df_1mil.loc[analysis_df_1mil['genre1'] == 'Sci-Fi']['year'].values, analysis_df_1mil.loc[analysis_df_1mil['genre1'] == 'Sci-Fi']['roi']),\n",
    "                               pd.Series(analysis_df_1mil.loc[analysis_df_1mil['genre2'] == 'Sci-Fi']['year'].values, analysis_df_1mil.loc[analysis_df_1mil['genre2'] == 'Sci-Fi']['roi']),\n",
    "                               pd.Series(analysis_df_1mil.loc[analysis_df_1mil['genre3'] == 'Sci-Fi']['year'].values, analysis_df_1mil.loc[analysis_df_1mil['genre3'] == 'Sci-Fi']['roi'])]\n",
    "                              )).reset_index().rename(columns={0:'year'})\n",
    "\n",
    "grouped_mean = genre_roi2_scifi.groupby('year').mean()\n",
    "\n",
    "ax = sns.lineplot(x= grouped_mean.index, y=grouped_mean.roi, data=grouped_mean)\n",
    "plt.ylim(0, 450000000)\n",
    "ax.set_title('Mean Return on Investment', fontsize = 17)\n",
    "ax.set_xlabel('Genre', fontsize=15);\n",
    "ax.set_ylabel('Return on Investment (in millons)', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[working_df['genres'].str.contains('Sci-Fi')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group by runtime_minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_runtime_grouped = analysis_df_1mil.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_runtime_grouped['runtime_desc'] = analysis_df_runtime_grouped.apply(\n",
    "    lambda x: 'short' if x['runtime_minutes'] <= 95.0 else(\n",
    "        'medium' if x['runtime_minutes'] <= 118.0 else 'long'), axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=analysis_df_runtime_grouped['runtime_desc'], y=analysis_df_runtime_grouped['roi'], data=analysis_df_runtime_grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for trends in Adventure/Sci-Fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_1mil.loc[((analysis_df_1mil['genre3'] == 'Sci-Fi') |\n",
    "                  (analysis_df_1mil['genre2'] == 'Sci-Fi') |\n",
    "                  (analysis_df_1mil['genre1'] == 'Sci-Fi') )&(\n",
    "                    (analysis_df_1mil['genre3'] == 'Adventure') |\n",
    "                    (analysis_df_1mil['genre2'] == 'Adventure') |\n",
    "                    (analysis_df_1mil['genre1'] == 'Adventure'))\n",
    "                 ].sort_values(by = 'roi', ascending=False).reset_index().style.apply(\n",
    "                lambda x: ['background: #00a4ef' if x.title == 'Inception' or x.title == 'Interstellar' else '' for i in x], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christopher Nolan movies are the only non-lisenced films on the list until number 49 - Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
